---
title: "Guía de comandos para el curso de WRF en HPC-CEDIA"
format: pdf
date: 2025-01-13
---

:::{.callout-note}

:::

# Instrucciones para acceso al cluster del CEDIA

Conectarse al HPC usando ssh: en windows se debe usar putty, en GNU/Linux se debe ssh en el terminal

```bash
ssh gabriel.gaona__ikiam.edu.ec@hpc.cedia.edu.ec
```

NOTA: Esto se debe hacer desde la computadora donde se creó la llave ssh de su usuario

# Reservar recursos para trabajar

EL HPC-CEDIA tiene diferentes nodos para conectarse. Debes aprender un poco en la guía de conexión para que puedas solicitar los recursos para tu sesión. Para reservar recursos para trabajar en el cluster del CEDIA se debe ejecutar el siguiente comando:

```bash
salloc -p cpu -n 2 -c 2  --mem=8GB --time=01:00:00
```

Si hay recusos disponibles y si la petición se ha hecho correctamente y existen los recursos disponibles en el cluster entces podrá ver un mensaje como el siguiente:

```
salloc: Pending job allocation 35713
salloc: job 35713 queued and waiting for resources
salloc: job 35713 has been allocated resources
salloc: Granted job allocation 35713
salloc: Waiting for resource configuration
salloc: Nodes dgx-node-0-0 are ready for job
```

Fíjese que la última línea indica el nodo que se ha asignado para que usted use. En este caso: "dgx-node-0-0"

# Ingresar al nodo asignado

Conéctese al nodo asignado usando ssh

```bash 
ssh dgx-node-0-0
```

# Crear una instancia de enroot para el modelo.

Esto se debe hacer una sola vez al inicio. Las siguientes ocasiones puedes saltarte estos pasos.

a. Importar imagen docker

```bash
enroot import docker://gabrielvgaona/curso-wrf:latest
```

b. Crear instancia WRF

```bash
enroot create --name wrf gabrielvgaona+curso-wrf+latest.sqsh
```

# Conectarse a la instancia del modelo.

```bash
enroot start --mount $HOME --root --rw wrf sh -c /bin/bash
```

Dentro de la instancia ya puedes instalar nano y descargar los scripts de datos

## Instalar nano

```bash
apt -y install nano
```

## Descargar los scripts de condiciones de borde

```bash
cd /home/gabriel.gaona__ikiam.edu.ec/
mkdir geodata/boundary-conditions/100
cd geodata/boundary-conditions/100
# descargar el listado de datos de condiciones de borde
wget -c https://raw.githubusercontent.com/gabrielvgaona/wrf-docker/refs/heads/main/home/rda-download_1.csh
# descargar los datos de condiciones de borde
csh rda-download_1.csh
```

Si quieres intentar resolver un ejercicio con mayor resolución puedes descargar estos datos:

NOTA: Esto no es necesario para el curso.

```bash
cd /home/gabriel.gaona__ikiam.edu.ec/
mkdir geodata/boundary-conditions/025
cd geodata/boundary-conditions/025
wget -c https://raw.githubusercontent.com/gabrielvgaona/wrf-docker/refs/heads/main/home/rda-download_0.25.csh
csh rda-download_1.csh
```

## Descargar datos geográficos para WPS

```bash
cd /home/gabriel.gaona__ikiam.edu.ec/geodata
wget -c https://www2.mmm.ucar.edu/wrf/src/wps_files/geog_high_res_mandatory.tar.gz
tar -xvf geog_high_res_mandatory.tar.gz
```

## Configurar WPS

Antes de modelar debemos configurar algunas cosas para el pre-procesamiento.

1. Configuración del `namelist.wps`

```bash
cd /WRF_ins/WPS
mv namelist.wps namelist.wps.bkp
wget -O namelist.wps https://raw.githubusercontent.com/gabrielvgaona/wrf-docker/refs/heads/main/home/namelist_wps_ejercicio.wps
nano namelist.wps
```
buscar la línea del parámetro `geog_data_path` y poner la ruta de los datos geográficos obligatorios para WPS. En mi caso sería: `'/root/geodata/WPS_GEOG'`.

```
geog_data_path = '/root/geodata/WPS_GEOG',
```

Para guardar los cambios presiona `[Ctrl]` + `[o]` y luego `[Ctrl]` + `[x]` para salir.

## Configurar WRF

De la misma manera, debemos agregar el fichero `namelist.input` en el directorio de `WRF`. Para hacer esto sigue estos pasos. En este paso te recomiendo revisar el artículo de [Bendix y Trachte (2015)](https://eva.ikiam.edu.ec/pluginfile.php/5056/mod_resource/content/3/trachte_bendix_WRF_Beck_etal_2017.pdf) y la [guía del NCAR](https://www2.mmm.ucar.edu/wrf/users/wrf_users_guide/build/html/namelist_variables.html#physics), para entender los parámetros del modelo. En etse caso también hemos preparado un fichero para el ejercicio de este curso.

```bash
cd /WRF_ins/WRF/run
mv namelist.input namelist.input.bkp
wget -O namelist.input https://raw.githubusercontent.com/gabrielvgaona/wrf-docker/refs/heads/main/home/namelist_wrf_ejercicio.txt
```

## Ejecutar el Preprocesamiento

1. Ejecutar geogrid.exe

```bash
cd /WRF_ins/WPS
./geogrid.exe
```

2. Crear enlaces simbólicos del los geogrids que se crearon a las condiciones de borde. Previamente debes conocer donde están los ficheros fnl: 

```bash
./link_grib.csh /root/geodata/boundary-conditions/100/fnl_*
```

3. Crear enlaces simbólicos a las tablas de variables de los datos de condiciones de borde en formato grib. En este caso usaremos datos de GFS por lo tanto tenemos que asegurarnos que sean las tablas para GFS. 

```bash
ln -sf ungrib/Variable_Tables/Vtable.GFS Vtable
```

4. Extraer las variables necesarias desde los ficheros grib de las condiciones de contorno

```bash
./ungrib.exe
```

5. Interpolar verticalmente las condiciones de contorno a distintos niveles de altitud.

```bash
./metgrid.exe
```

## Ejecutar el modelamiento

Crear enlaces simbólicos hacia el mallado con las condiciones de borde (ficheros met creados con metgrid.exe).

```bash
cd WRF_ins/WRF/run
ln -sf /WRF_ins/WPS/met_em* .
```

Ejecutar las configuraciones para simulación de un evento real. **Este paso puede tomar un tiempo considerable**, dependiendo de los recursos que haya reservado en el cluster.

```bash
./real.exe
```

Ejecutar el modelo para todas las configuraciones realizadas. Ejecutar las configuraciones para simulación de un evento real. **Este paso puede tomar un tiempo bastante largo**, dependiendo de los recursos que haya reservado en el cluster.

```bash
./wrf.exe
```

# Postprocesamiento

En este punto ya debes tener listo un resultado del modelamiento para que puedas analizar. Empecemos copiando los resultados entre diferentes sesiones.

## Copiar resultado WRF al home del usuario en CEDIA.

Dentro de la instancia `wrf` debes ejecutar el comando cp para hacer una copia de los resultados del modelo a tu home compartido:

```bash
mkdir /home/gabriel.gaona__ikiam.edu.ec/geodata/wrf-salida
cd /home/gabriel.gaona__ikiam.edu.ec/geodata/wrf-salida
cp WRF_ins/WRF/run/wrfout_* .
```

## Copiar desde host remoto (cedia) a la máquina local

Esto es diferente entre MS Windows y GNU/Linux. Intentaremos explicar cada uno por separado

- Copiar archivos desde GNU/Linux

```bash 
cd ruta/a/directorio/local #poner la ruta del directorio local
scp gabriel.gaona__ikiam.edu.ec@hpc.cedia.edu.ec:/home/gabriel.gaona__ikiam.edu.ec/geodata/wrf-salida/wrfout_* .
```
- Copiar archivos desde Windows
    + Renombrar los archivos para cambiar los dos puntos por guión bajo. Esto es necesario porque windows no permite que se use el caracter dos-puntos (:) en los nombres de los archivos

```bash
# Dentro del cluster
cd /home/gabriel.gaona__ikiam.edu.ec/geodata/wrf-salida
for f in $(ls wrfout*); do mv $f "${f//:/_}"; done
```

    + Abrir el `cmd` de Windows

```bash 
cd c:/ruta/carpeta/instacion/putty #poner la ruta del directorio local
pscp.exe -i ruta/llave/privada.ppk gabriel.gaona__ikiam.edu.ec@hpc.cedia.edu.ec:/home/gabriel.gaona__ikiam.edu.ec/geodata/wrf-salida/wrfout_* c:/ruta/a/directorio/local/.
```

